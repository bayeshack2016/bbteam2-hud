{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pickle\n",
    "import nltk\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction import text\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from nltk.corpus import stopwords\n",
    "stops = set(stopwords.words('english'))\n",
    "punc = set(string.punctuation)\n",
    "for sw in punc:\n",
    "    stops.add(sw)\n",
    "\n",
    "dir_ = r\"C:\\Users\\Broccoli\\Documents\\Bayes Hack\"\n",
    "#hp2014 = pickle.load(open(dir_ + r\"\\housing_pipeline_2014_comments.pkl\", \"rb\"))\n",
    "hi2014 = pickle.load(open(dir_ + r\"\\housing_inventory_2014_comments.pkl\", \"rb\"))\n",
    "hi2013 = pickle.load(open(dir_ + r\"\\housing_inventory_2013_comments.pkl\", \"rb\"))\n",
    "hi2012 = pickle.load(open(dir_ + r\"\\housing_inventory_2012_comments.pkl\", \"rb\"))\n",
    "hi2011 = pickle.load(open(dir_ + r\"\\housing_inventory_2012_comments.pkl\", \"rb\"))\n",
    "\n",
    "comments = {}\n",
    "for d in [hi2014,hi2013,hi2012,hi2011]:\n",
    "    for k,v in d.items():\n",
    "        comments[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iter_comments(comments=comments):\n",
    "    for prj in comments:\n",
    "        for article in comments[prj]:\n",
    "            for c in article['comments']:\n",
    "                yield ' '.join([''.join(ch for ch in w if ch not in punc).lower().replace('\\n','') for w in c.split(' ')])\n",
    "\n",
    "com2prj = []\n",
    "for prj in comments:\n",
    "    for article in comments[prj]:\n",
    "        [com2prj.append(prj) for c in range(0,len(article['comments']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sentiment_pred(sentence):\n",
    "    from nltk.corpus import opinion_lexicon\n",
    "    from nltk.tokenize import treebank\n",
    "#    with open(dir_+r'\\negative.txt', 'r') as f:\n",
    "#        negative = set(f.read().split('\\n'))\n",
    "    negative = opinion_lexicon.negative()\n",
    "    tokenizer = treebank.TreebankWordTokenizer()\n",
    "    pos_words = 0\n",
    "    neg_words = 0\n",
    "    tokenized_sent = [word.lower() for word in tokenizer.tokenize(sentence) if word not in stops]\n",
    "    x = list(range(len(tokenized_sent))) # x axis for the plot\n",
    "    y = []\n",
    "    for word in tokenized_sent:\n",
    "        if word in opinion_lexicon.positive():\n",
    "            pos_words += 1\n",
    "            y.append(1) # positive\n",
    "        elif any(n in word for n in negative):\n",
    "            neg_words += 1\n",
    "            y.append(-1) # negative\n",
    "        else:\n",
    "            y.append(0) # neutral\n",
    "    if pos_words > neg_words:\n",
    "        return 1\n",
    "    elif pos_words < neg_words:\n",
    "        return -1\n",
    "    elif pos_words == neg_words:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics = [\n",
    "            [\"safe\",\"secur\",\"hurt\",\"crime\",\"protect\",\"thie\",\"graffiti\",\"drug\",\"attack\",\"arrest\",\"danger\",\"murder\",\"theft\",\"violen\",\"rate\",\"fear\"],\n",
    "            [\"congestion\",\"parking\",\"space\",\"car\",\"more\",\"street\",\"garage\",\"spot\"],\n",
    "            [\"bike\",\"transit\",\"muni\",\"cycl\",\"commut\",\"mta\",\"bus\",\"bart\",\"walk\",\"subway\",\"transportation\",\"bart\",\"station\"],\n",
    "            [\"homeless\",\"grim\",\"problem\",\"encamp\",\"bum\",\"ghetto\",\"alcohol\"],\n",
    "            [\"school\",\"kid\",\"famil\",\"public\",\"activit\",\"stud\",\"class\",\"private\"],\n",
    "            [\"green\",\"emission\",\"gas\",\"environment\",\"natur\",\"noise\",\"traffic\",\"mph\",\"pollution\"],\n",
    "            [\"prop\",\"13\",\"landlord\",\"ellis\",\"evict\",\"rent\",\"subsid\",\"tenant\",\"pay\",\"market\",\"afford\",\"bmr\"],\n",
    "            [\"ceqa\",\"development\",\"approv\",\"review\",\"appeal\",\"commission\",\"permit\"],\n",
    "            [\"height\",\"tower\",\"high\",\"stor\",\"apartment\",\"tall\",\"dens\",\"bonus\"],\n",
    "            [\"register\",\"vote\",\"tax\",\"elect\",\"ballot\",\"bond\",\"politic\",\"campaign\"],\n",
    "            [\"elite\",\"compan\",\"gentrif\",\"rich\",\"tech\",\"wealth\"]\n",
    "        ]\n",
    "\n",
    "def topic_sentiment_scores(projects, comments=comments):\n",
    "    for prj in comments:\n",
    "            topic_scores = []\n",
    "            sentiment = 0\n",
    "            if comments[prj]:\n",
    "                projects[prj] = {'comments': list(), 'number_of_comments': 0}\n",
    "                for article in comments[prj]:\n",
    "                    for comment in article['comments']:\n",
    "                        projects[prj]['number_of_comments'] += 1\n",
    "                        topic = [sum([tw in w for tw in tpc for w in comment.split(' ')]) for tpc in topics]\n",
    "                        topic_scores.append(topic)\n",
    "                        comment_sent = sentiment_pred(''.join([ch for ch in comment if ch not in punc]))\n",
    "                        projects[prj][\"comments\"].append({'comment': comment, \"topic\": topic, \"sentiment\": comment_sent})\n",
    "                        sentiment += comment_sent\n",
    "                projects[prj][\"topic\"] = sum(np.array(topic_scores))\n",
    "                projects[prj][\"sentiment\"] = sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "projects = defaultdict(dict)\n",
    "\n",
    "topic_sentiment_scores(projects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(projects, open(dir_ + r\"\\topics_and_sentiment.pkl\", \"wb\")) \n",
    "pickle.dump(topics, open(dir_ + r\"\\topic_key.pkl\", \"wb\")) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
